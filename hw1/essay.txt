	Artificial intelligence has rapidly evolved to the point where even the general public has been allowed access to artificial intelligence in the form of LLMs such as ChatGPT and GPT-4. As seen through the development of LLMs, it is clear that artificial intelligence has the potential to continue and improve in ways that cannot be predicted. On the other hand, it is actually unclear as to what artificial intelligence has already accomplished. As discussed in section 10 of the AI100 report, one of the most pressing dangers of artificial intelligence is its lack of transparency to the general public. Similarly, Microsoft’s report on GPT-4’s intelligence shows that their developers intentionally restrict what public LLMs can or cannot do to prevent misinformation and manipulation; in one of their examples, GPT-4 demonstrates its ability to manipulate a child into doing something that they are not comfortable with, showing how LLMs could be used to inflict harm on others if not given any limitations. The important detail to note here is that LLMs are capable of a lot more than the public is given access to. Developers of LLMs have access to these dangerous capabilities, which makes it difficult to imagine how they might be using unrestricted/prototype LLMs to control what the public knows about artificial intelligence.

	In 2023, Belinda Scrimenti wrote an article pointing out the many legal problems surrounding artificial intelligence, including how the law is not quite caught up with the advancements of artificial intelligence. She also claimed that any artificially generated “synthesized version” of a celebrity could be used to cause confusion among the general public. The combination of these two issues spells potential for chaos in the near future. As discussed, the public view on artificial intelligence is very heavily influenced by developers. To emphasize this point, consider the ability of artificial intelligence to create synthesized versions of people. There are many examples of artificially generated social media profiles that can be identified as artificially generated once examined closely enough, but this gives the public a false sense of control in being able to tell the difference between authentic and artificial products; while the public can prove that a given profile is artificial, it is much more difficult for the public to prove that it is authentic. It is possible (and very likely) that artificial intelligence has already reached a higher level of precision that the public is not aware of. To judge whether something is artificial or not, one might look for evidence through other online sources. Unfortunately, it is very easy to generate false information online, even without the use of artificial intelligence.

	The evolution of artificial intelligence is happening faster than expected. Through the AI100 report as well as Microsoft’s report on GPT-4’s intelligence, it can be understood that the public knowledge of artificial intelligence is incomplete and controlled by the developers of artificial intelligence. Furthermore, the public is very likely to be interacting with artificial intelligence much more than they realize, as it is difficult to determine the authenticity of a given profile when artificially generated social media profiles exist. Artificial intelligence may already be far more advanced than the public understands it to be; the next major advancement of artificial intelligence might have already happened. When the public realizes that it is impossible to differentiate between real and fake, there will definitely be a lot of authentic confusion.
